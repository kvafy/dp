%============================================================================
% tento soubor pouzijte jako zaklad
% (c) 2008 Michal Bidlo
% E-mail: bidlom AT fit vutbr cz
%============================================================================
% kodovaní: utf-8 (zmena prikazem iconv, recode nebo cstocs)
%----------------------------------------------------------------------------
% zpracování: make, make pdf, make desky, make clean
% připomínky posílejte na e-mail: bidlom AT fit.vutbr.cz
% vim: set syntax=tex encoding=utf-8:
%============================================================================
\documentclass[english,cover]{fitthesis} % odevzdani do wisu - odkazy, na ktere se da klikat
%\documentclass[cover,print]{fitthesis} % pro tisk - na odkazy se neda klikat
%\documentclass[english,print]{fitthesis} % pro tisk - na odkazy se neda klikat
%      \documentclass[english]{fitthesis}
% * Je-li prace psana v anglickem jazyce, je zapotrebi u tridy pouzit 
%   parametr english nasledovne:
%      \documentclass[english]{fitthesis}
% * Neprejete-li si vysazet na prvni strane dokumentu desky, zruste 
%   parametr cover

% zde zvolime kodovani, ve kterem je napsan text prace
% "latin2" pro iso8859-2 nebo "cp1250" pro windows-1250, "utf8" pro "utf-8"
%\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage[T1, IL2]{fontenc}
\usepackage{url}
\DeclareUrlCommand\url{\def\UrlLeft{<}\def\UrlRight{>} \urlstyle{tt}}

%zde muzeme vlozit vlastni balicky
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{color}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\newtheorem{math_def}{Definition}[chapter] % 3. parametr zajisti cislovani "<sekce>.<číslo definice>"
\newcommand{\term}[1]{\emph{#1}}           % novy termin v textu prace
\newcommand{\todo}[1]{{\color{red}TODO: #1}}
\newcommand{\uncertain}[1]{{\color{magenta} #1}}
\newcommand{\note}[1]{{\color{green} #1}}
\newcommand{\vars}[1]{{\mathbf{#1}}} % matematicke vyrazy - mnozina
\newcommand{\ignore}[1]{} % komentar v radku
% SP komentar co se hodi zohlednit ve finalni diplomce


% =======================================================================
% balíček "hyperref" vytváří klikací odkazy v pdf, pokud tedy použijeme pdflatex
% problém je, že balíček hyperref musí být uveden jako poslední, takže nemůže
% být v šabloně
\ifWis
\ifx\pdfoutput\undefined % nejedeme pod pdflatexem
\else
  \usepackage{color}
  \usepackage[unicode,colorlinks,hyperindex,plainpages=false,pdftex]{hyperref}
  \definecolor{links}{rgb}{0.4,0.5,0}
  \definecolor{anchors}{rgb}{1,0,0}
  \def\AnchorColor{anchors}
  \def\LinkColor{links}
  \def\pdfBorderAttrs{/Border [0 0 0] }  % bez okrajů kolem odkazů
  \pdfcompresslevel=9
\fi
\fi

%Informace o praci/projektu
%---------------------------------------------------------------------------
\projectinfo{
  %Prace
  project=DP,            %typ prace BP/SP/DP/DR
  year=2012,             %rok
  date=\today,          %datum odevzdani
  %Nazev prace
  title.cs={Aplikace Bayesovských sítí},  %nazev prace v cestine
  title.en={Bayesian Networks Applications}, %nazev prace v anglictine
  %Autor
  author={David Chaloupka},   %jmeno prijmeni autora
  author.title.p=Bc., %titul pred jmenem (nepovinne)
  %author.title.a=PhD, %titul za jmenem (nepovinne)
  %Ustav
  department=UITS, % doplnte prislusnou zkratku: UPSY/UIFS/UITS/UPGM
  %Skolitel
  supervisor=František V. Zbořil, %jmeno prijmeni skolitele
  supervisor.title.p=doc.~Ing.,   %titul pred jmenem (nepovinne)
  supervisor.title.a={CSc.},    %titul za jmenem (nepovinne)
  %Klicova slova, abstrakty, prohlaseni a podekovani je mozne definovat 
  %bud pomoci nasledujicich parametru nebo pomoci vyhrazenych maker (viz dale)
  %===========================================================================
  %Klicova slova
  keywords.cs={Bayesovská síť, pravděpodobnost, inference, učení struktury.}, %klicova slova v ceskem jazyce
  keywords.en={Bayesian network, probability, inference, structure learning.}, %klicova slova v anglickem jazyce
  %Abstract
  abstract.cs={Tato diplomová práce se zabývá možnými aplikacemi Bayesovských sítí. Nejprve se zaměřuje na obecnou teorii pravděpodobnosti, později na úrovni matematiky vysvětluje samotnou teorii Bayesovských sítí, přístupy k inferenci a k učení včetně pochopení silných a~slabých stránek daných technik. V praktické části je kladen důraz na aplikace vyžadující učení Bayesovské sítě, jednak ve smyslu učení parametrů a jednak ve smyslu struktury.}, % abstrakt v ceskem jazyce
  abstract.en={This master's thesis deals with possible applications of Bayesian networks. The theoretic part is mainly of mathematical nature. At first, we focus on general probability theory and later we move on to the theory of Bayesian networks and discuss approaches to inference and to model learning while providing an explanation of pros and cons of these techniques. The practical part focuses on applications suitable for learning a Bayesian network, both in terms of network parameters as well as structure.}, % abstrakt v anglickem jazyce
  %Prohlaseni
  declaration={Prohlašuji, že jsem tento semestrální projekt vypracoval samostatně pod vedením pana doc.~Ing. Františka V. Zbořila, CSc.},
  %Podekovani (nepovinne)
  acknowledgment={Na tomto místě bych rád poděkoval svému vedoucímu, docentu Františku V. Zbořilovi, za cenné rady, odborné vedení a vstřícný přístup v nesnázích při řešení této práce.} % nepovinne
}

%Abstrakt (cesky, anglicky)
%\abstract[cs]{Do tohoto odstavce bude zapsán výtah (abstrakt) práce v českém jazyce.}
%\abstract[en]{Do tohoto odstavce bude zapsán výtah (abstrakt) práce v anglickém jazyce.}

%Klicova slova (cesky, anglicky)
%\keywords[cs]{Sem budou zapsána jednotlivá klíčová slova v českém jazyce, oddělená čárkami.}
%\keywords[en]{Sem budou zapsána jednotlivá klíčová slova v anglickém jazyce, oddělená čárkami.}

%Prohlaseni
%\declaration{Prohlašuji, že jsem tuto bakalářskou práci vypracoval samostatně pod vedením pana X...
%Další informace mi poskytli...
%Uvedl jsem všechny literární prameny a publikace, ze kterých jsem čerpal.}

%Podekovani (nepovinne)
%\acknowledgment{V této sekci je možno uvést poděkování vedoucímu práce a těm, kteří poskytli odbornou pomoc
%(externí zadavatel, konzultant, apod.).}

\begin{document}
  % Vysazeni titulnich stran
  % ----------------------------------------------
  \maketitle
  % Obsah
  % ----------------------------------------------
  \tableofcontents
  
  % Seznam obrazku a tabulek (pokud prace obsahuje velke mnozstvi obrazku, tak se to hodi)
  % \listoffigures
  % \listoftables 

  % Text prace
  % ----------------------------------------------

  








%end-of-inserted-header
%=========================================================================
% (c) Michal Bidlo, Bohuslav Křena, 2008

\chapter{Introduction}

Bayesian networks represent a subclass of probabilistic graphical models and serve as a~tool for modeling joint probability distributions of random variables. Bayesian networks were originally used to evaluate medical data of a patient in order to determine the probability of them having a certain disease\,--\,a situation with many unknown facts, eg. missing medical history or unknown results of possible tests. Since then there have been many other applications such as inspection of pedigree trees in genetics or general classification tasks.

The main advantage of Bayesian networks lies in their inherent property that, thanks to conditional dependency and independency between variables, they represent the joint probability distribution in a very compact way in terms of space complexity. Construction of Bayesian networks for some concrete problem is a complicated process involving complex algorithms, enough input data and, in many cases, expert knowledge. Another problem is providing answers to queries over the underlaying probability distribution of a Bayesian network, so called inference.

The aim of this thesis is to present techniques of learning Bayesian networks, both in terms of conditional probability tables as well as in terms of structure and to show possible application domains. Inference is narrowed down to stochastic approaches because other ways are complex even in the most basic form. Still, all approaches to inference will be mentioned at least on the level of basic concept, since it is a fundamental part of the theory of Bayesian networks.

\medskip

Chapter 2 serves as an introduction to the fundamentals of the probability theory and provides necessary foundations for understanding the rest of this thesis and an overview of the notation used.

Chapter 3 discusses the theory of Bayesian networks. First we explain the main motivation for using Bayesian networks as a model for joint probability distributions. Then we move on to various inference methods and finally discuss model learning techniques in terms of model parameters and in terms of model structure.

In chapter 4 I will describe details of the program realization of this thesis. There will be presented used data structures, algorithms and the overall architecture of the final application.
This part is yet to be worked on. % SP

Chapter 5 discusses selected applications suitable for parameter and structure learning of Bayesian networks. This part is to be one of the main interests of the summer semester.

The final chapter summarizes the overall achieved results of this term project and discusses further planned work.































\chapter{Preliminaries}
This chapter will present theoretical foundations for understanding Bayesian networks and performing computation over them. Studying Bayesian networks (further abbreviated as BNs) is challenging both because of necessary mathematical rigor as well as for the need of efficient non-trivial algorithms to construct them and to provide answers for probability queries. In some cases the mathematical derivation will be presented because, I believe, it provides useful insight into the underlaying theory. In other cases we will jump straight to the practical conclusion needed in order to algorithmically solve the problem at hand because the derivation is either very difficult or the process itself is uninteresting for a~non-mathematician and would rather obfuscate the topic.

First will be established notation used in this thesis and necessary overview of probability theory. Then we will move on to the theory of Bayesian networks, explain their advantages and proceed to inference and construction techniques.



\section{Philosophical views}
Probability is usually interpreted as degree of belief in occurrence of a particular event, eg. probability of a fair die rolling a six is $1/6$. Although probability is expressed as a~real number between zero and one, the ground truth is that in the end one and only one \emph{concrete} event is observed. In the case of a die, one concrete number is rolled regardless what the probabilities were. Although our intuition and general experience proves it to be true in our macroscopic world, objects in the microscopic world of quantum mechanics actually are probabilistic in nature and, a particle for example, is in many quantum states at the same time. The particle is then described by a complex \term{wave function} $\Psi(x,y,z,t)$ and $\vert\Psi(\cdot)\vert^2$ describes \term{density probability} of the particle as a function of space-time coordinates~\cite[p.~1044]{hrw_physics}. Despite the obvious differences, certain qualities of both these worlds can be described by the same mathematical apparatus which is probability theory.

Somewhat close to probability theory is the theory of fuzzy sets which operates with membership functions. These functions describe degrees of truth, eg. that a person is regarded as young or old. The main difference, when compared to probability, is that in fuzzy sets theory an object may have more than one quality to some degree and there is no ground truth or observation that would strictly place a person into one single category.


\section{Probability distributions}
Let's begin by defining what a probability distribution is when there is only one single random variable.
\begin{math_def}\label{def_prob_distribution}
    $P(X)$ is discrete probability distribution of discrete random variable $X$ such that:
    \begin{itemize}
        \item $X$ can be assigned any value from the set $Val(X) = \lbrace x_1, x_2, \dots \rbrace$ which is finite or denumerable.
        \item $\forall i: P(X = x_i) \geq 0$
        \item $\Bigl( \sum_i P(X = x_i) \Bigr) = 1$
    \end{itemize}
\end{math_def}

Notice that random variables are denoted by capital letters $X, Y, E$ etc., concrete values of random variables (instantiations) are denoted by small letters such as $x$. Further we will use bold capital letters to denote sets of random variables such as $\vars{X}$ and their instantiation with bold small letters such as $\vars{x}$.

Probability distributions of more than one random variable are called \term{joint probability distributions}. For example if we were to study a simultaneous throw with two dices, black and white, we would get joint probability distribution $P(X_{black},X_{white})$. In this probability distribution we know how likely every single outcome of a throw is. In this case there are $6 \times 6 = 36$ possibilities so the $P(X_{black},X_{white})$ function would have 36 entries if represented by a table.

So far we have described so called \term{prior probabilities} which are applicable in situations when no observation has been made and hence everything is governed purely by probability. If, on the other hand, we know concrete value of some random variable then we speak about \term{posterior probability} or \term{conditional probability}.
Posterior and prior probability distributions are not the same in general because observation of a~variable may affect distribution of other variables as we will see later in context of flow of probabilistic influence in Bayesian networks.
Conditional probability distribution of variables $\vars{X}$ depending on variables $\vars{E}$ is denoted $P(\vars{X}\mid\vars{E})$ and such expression is usually read as "probability of $\vars{X}$ given $\vars{E}$" where $\vars{E}$ are called \term{evidence} or \term{observed} variables. Conditional probability distribution can be seen as a collection of probability distributions over variables $\vars{X}$ for every possible instantiation of variables $\vars{E}$.


\section{Factors}
When reasoning about Bayesian networks we express probability distributions as so called \term{factors}. Factors are interesting for us because factor operations correspond to mathematical operations we need to do with probability distributions in order to answer queries in a~Bayesian network. 
\begin{math_def}\label{def_factor}
    Factor $\phi$ is a function $\phi: X_1 \times X_2 \times \dotsm \times X_k \rightarrow \mathbb{R}_0^+$. The non-empty set $\lbrace X_1, X_2, \dots, X_k \rbrace$ is called scope of the factor $\phi$.
\end{math_def}
According to the definition of a factor and to the definition \ref{def_prob_distribution} of a discrete probability distribution, probability distributions are special cases of factors. They both require their values to be non-negative and, in addition, every probability distribution must sum to one. A~factor, of course, may sum to one too in which case we say it is \term{normalized}.

There are 4 operations over factors we will need further in this thesis\,--\,pointwise product, marginalization, conditioning and renormalization. Definitions below are inspired by description of these operations in~\cite{russell_norvig_ed2, pgm}

\subsubsection{Pointwise product}
Pointwise product of factors $\phi_1$ and $\phi_2$ is a factor $\psi$, denoted $\psi = \phi_1 \cdot \phi_2$, defined as follows. The scope of $\psi$ is $scope(\phi_1) \cup scope(\phi_2)$. Let $scope(\phi_1) = \lbrace X_1, \dots, X_m, Y_1, \dots, Y_n \rbrace$ and $scope(\phi_2) = \lbrace Y_1, \dots, Y_n, Z_1, \dots, Z_k \rbrace$ where $\lbrace X_1, \dots, X_m \rbrace$ and $\lbrace Z_1, \dots, Z_k \rbrace$ are disjoint. For every assignment $x_1, \dots, x_m, y_1, \dots, y_n, z_1, \dots, z_k$ of variables in $scope(\psi)$ the value of $\psi$ is given as:
$$\psi(x_1, \dots, x_m, y_1, \dots, y_n, z_1, \dots, z_k)
= \phi_1(x_1, \dots, x_m, y_1, \dots, y_n) \cdot \phi_2(y_1, \dots, y_n, z_1, \dots, z_k)
$$

Please note that it is also possible for the sets $\lbrace X_i \rbrace, \lbrace Y_i \rbrace,\lbrace Z_i \rbrace$ to be empty (of course, according to the definition~\ref{def_factor}, factor must have at least one variable in its scope).

Factor representation of a joint probability distribution $P(X,\dots,Z)$ is straightforward\,--\,simply put $\phi(x,\dots,z) = P(x,\dots,z)$ for every assignment $x,\dots,z$ of variables $X,\dots,Z$. In this case probabilities of all possible assignments must necessarily sum to one since $P(X,\dots,Z)$ is a~probability distribution. For further reference, this summation is denoted $\sum_{X,\dots,Z} P(x,\dots,z) = 1$.

Let's examine the case of a conditional probability distribution $P(\vars{X}\mid\vars{E})$. Suppose that, according to the established notation, $\vars{X}$ and $\vars{E}$ are sets of variables rather than single variables. Then $scope(\phi)$ is $\vars{X} \cup \vars{E}$ but probability of all possible assignments to $\vars{X}$ and $\vars{E}$ doesn't sum to one! This is because the conditional probability distribution $P(\vars{X}\mid\vars{E})$ is more like a collection of probability distributions of variables $\vars{X}$ for every assignment to $\vars{E}$. So, for any concrete assignment $\vars{e}$ of evidence variables $\vars{E}$, the probability distribution $P(\vars{X}\mid\vars{e})$ again sums to one, ie. $\sum_\vars{X} P(\vars{x}\mid\vars{e}) = 1$.

\subsubsection{Marginalization}
Marginalization of a factor $\phi$ over variables $\vars{Y}$ is operation of summing out these variables, effectively producing factor $\psi$. Then $scope(\psi) = scope(\phi) \setminus \vars{Y}$ and for every assignment $\vars{x}$ of variables in $scope(\phi)$ holds that $\psi(\vars{x}) = \sum_\vars{Y} \phi(\vars{x},\vars{y})$.

\subsubsection{Conditioning}
Conditioning is operation used when there is some observed evidence $\vars{e}$ of variables $\vars{E}$. By conditioning we set probabilities of all events inconsistent with observed evidence to 0. Of~course the resulting factor will not be normalized in general.

\subsubsection{Renormalization}
Renormalization of a factor $\phi$ ensures that all values of the factor sum to one. Suppose that $\vars{X} = scope(\phi)$ and let $\alpha = \sum_\vars{X} \phi(\vars{x})$ be normalizing constant. Values of the resulting factor $\psi$ are given for every assignment $\vars{x}$ of variables $\vars{X}$ as $\psi(\vars{x}) = \phi(\vars{x}) / \alpha$.

It may be useful to point out that renormalization makes sense only for factors that don't represent conditional probability distributions.



































\chapter{Theory of Bayesian networks}
In this chapter we will first discuss the reasons for using Bayesian networks. Then we will move on to various inference methods and to methods of model learning, both in terms of model parameters as well as in terms of structure.

Question might be why to use Bayesian networks? First of all, having a complicated joint probability distribution with many random variables inevitably leads to a potentially enormously large table that would represent such probability distribution. Let's assume we have binary random variables $X_1, \dots, X_k$. Then to represent the joint probability distribution $P(X_1, \dots, X_k)$ we would need a table with $2^k$ entries. This exponential growth brings several problems:
\begin{itemize}
    \item Table completely describing a joint probability distribution may be too big to store. That is because the table would hold probability of every possible event separately in its own record.
    \item Even if the table could be stored, performing calculations over it (e.g. factor marginalization or factor multiplication) would not be efficient. In fact, operations such as exact inference are known to be NP-hard in the number of variables~\cite{pgm}.
    \item In order to construct probability table for a joint probability distribution:
    \begin{enumerate}
        \item[a)] We would require huge amount of training data to create an accurate statistical model from, since we would essentially count occurrences of every single event (ie. of possible instantiations of all random variables) and finally divide these counts by the total number of all training examples.
        \item[b)] We would need a human expert to determine the probability of every possible assignment to random variables. This is generally not possible because all probabilities would be near to zero and human experts are simply not able to correctly capture probabilities on this level~\cite{pgm}.
    \end{enumerate}
\end{itemize}

As will be shown later, Bayesian networks couple with the problem of exponential growth of records in probability tables by having several smaller conditional probability distributions (factors) based on dependencies between random variables. Product of all these conditional probabilities (factors) gives the underlaying joint probability distribution which would, if represented directly, require an exponentially bigger table.



\begin{math_def}\label{def_bayesian_network}
    Bayesian network $G$ is a directed acyclic graph where each node represents a~random variable and oriented edges between nodes express direct dependencies between random variables.
\end{math_def}

The definition of Bayesian network (further abbreviated BN) implies several things. Acyclic and directed properties tell us that there is a hierarchy of nodes in terms of parent-child relation, meaning that child random variable $C$ is dependent on its parent random variables $P_1, \dots, P_m$ (also denoted $Parents(C)$). This conditional probability distribution $P(C \mid Parents(C))$ is usually\footnote{For purposes of this thesis, we assume probability distributions of discrete, not continuous, variables whose events are from a finite set. Such probability distribution can be expressed by a table.} expressed via a \term{Conditional Probability Table (CPT)} that defines probability distribution of variable $C$ for every possible assignment of variables $Parents(C)$. Of course, for every assignment $p_1,\dots,p_m$ of variables $Parents(C)$ must hold that $\sum_C P(c \mid p_1, \dots, p_m) = 1$. Otherwise $P(C \mid Parents(C))$ would not be a probability distribution (by definition~\ref{def_prob_distribution}).

We say that Bayesian network $G$ with nodes $\lbrace X_1, \dots, X_k\rbrace$ induces joint probability distribution $P(X_1, \dots, X_k)$ as follows:
\begin{equation}\label{eq:bn_joint}
    P(X_1, \dots, X_k) = \prod_{i=1}^k P(X_i \mid Parents(X_i))
\end{equation}
Equivalent statement is that $P(X_1, \dots, X_k)$ factorizes over BN $G$ if the equation \eqref{eq:bn_joint} holds. This is because the terms $P(X_i \mid Parents(X_i))$ are \term{factors} and by constructing a~Bayesian network we can factorize otherwise very space-consuming CPD of $P(X_1, \dots, X_k)$ into several smaller CPDs $P(X_i \mid Parents(X_i))$, one for every node $X_i$.

I have devised a proof that $P(X_1, \dots, X_k)$ induced by a BN $G$ is indeed a probability distribution, when assuming that every factor $P(X_i \mid Parents(X_i))$ in $G$ is also a probability distribution. Main purpose of this proof is to provide the reader with some familiarity when mathematically reasoning about BNs because similar tricks will be used later on. Core of the proof is to show that both axioms of a probability distribution (Definition \ref{def_prob_distribution}) are satisfied\footnote{Because of long expressions in the following two paragraphs, $Pars(X)$ denotes $Parents(X)$.}:
\begin{enumerate}
   \item $P(X_1, \dots, X_k) \geq 0$:
       Trivial since factors $P(X_i \mid Parents(X_i))$ are assumed to be valid probability distributions. Then, by definition of probability distribution~\ref{def_prob_distribution}, we know that $\forall i: P(X_i \mid Parents(X_i)) \geq 0$. And product of non-negative numbers (factors) is also non-negative, ie. $\prod_{i=1}^k P(X_i \mid Parents(X_i)) \geq 0$.
   \item $\sum P(x_1, \dots, x_k) = 1$:
       If the remaining variables $X_1, \dots, X_k$ are all independent, then by definition of independent random variables $P(X_1, \dots, X_k) = P(X_1) \dotsm P(X_k)$. So the sum can be written as $\sum P(x_1, \dots, x_k) = \sum_{X_1} P(x_1) \sum_{X_2} P(x_2) \dotsm \sum_{X_k} P(x_k)$. By assumption, all factors are valid probability distributions, so $\sum_{X_k} P(x_k) = 1$. Then $\sum_{X_1} P(x_1) \sum_{X_2} P(x_2) \dotsm \sum_{X_k} P(x_k) = \sum_{X_1} P(x_1) \sum_{X_2} P(x_2) \dotsm 1$. Thus we have eliminated variable $X_k$ and transformed the problem to $\sum P(x_1, \dots, x_{k-1}) = 1$. By eliminating all remaining variables the same way, we get $\sum P(x_1, \dots, x_k) = 1$.
       
       If there is a direct dependency between some two variables let's relabel the variables so that their indices correspond to a topological sort of the given BN (every BN is a~DAG, so a topological sort exists).  Then we can rewrite the inspected summation in the form $\sum P(x_1, \dots, x_k) = \sum_{X_1} P(x_1 | Pars(X_1)) \sum_{X_2} P(x_2 | Pars(X_2)) \dotsm \sum_{X_k} P(x_k | Pars(X_k))$ because, thanks to the topological sort, all parent variables of a variable $X_i$ must have smaller index that $i$. Also note that the maximal element $X_k$ has no child. By assumption, $P(X_k \mid Pars(X_k))$ is a probability distribution, so $\sum_{X_k} P(x_k \mid Pars(X_k)) = 1$. By substituting the term $\sum_{X_k} P(x_k \mid Pars(X_k))$ in the summation we eliminate the variable $X_k$ and transform the problem to question if $\sum P(x_1, \dots, x_{k-1}) = 1$ which we approach analogically.
\end{enumerate}


\section{Flow of probabilistic influence}
To describe how observing certain facts propagates through a Bayesian network and how it affects probability distributions of unobserved variables on qualitative level, let's introduce \term{flow of probabilistic influence}. Flow of influence also enables us to formally capture conditional dependency and/or independency of random variables in a BN given some facts.
\begin{math_def}
    Let $G$ be a Bayesian network with nodes $X_1, X_2, \dots, X_k$ and let $\vars{Z}$ be a~set of observed variables. Connected undirected trail $X_a - X_{a+1} - \dots - X_b$ given facts $\vars{Z}$ is active iff
    \begin{itemize}
        \item For every so called "V-structure" $X_{i-1} \rightarrow X_i \leftarrow X_{i+1}$ on the trail is $X_i \in \vars{Z}$.
        \item No other node of given trail is in $\vars{Z}$.
    \end{itemize}
    Notes: V-structure is defined as a segment of trail in form $X_{i-1} \rightarrow X_i \leftarrow X_{i+1}$ (in this case, edge directions do matter). Also note that the trail may contain duplicate nodes.
\end{math_def}

\begin{math_def}
    Let $G$ be a Bayesian network, $X,Y$ two of its nodes and $\vars{Z}$ observed variables. We say that $X,Y$ given $\vars{Z}$ are d-separated in $G$ iff there is no active trail between $X$ and $Y$ given $\vars{Z}$.
    
    Note: $X$ and $Y$ being d-separated given $\vars{Z}$ is equivalent to $X$ and $Y$ being conditionally independent given $\vars{Z}$, denoted $X \perp Y \mid \vars{Z}$.
\end{math_def}

By using d-separation (direction-dependent separation) we can quite elegantly determine if observation of a variable $X$ can or cannot affect distribution of some other random variable. Clearly two random variables that are directly connected are dependent. But we can also examine other than these intuitively obvious relations. Also, please note that whether two random variables $X,Y$ are independent in Bayesian network depends on our observations $\vars{Z}$ as it can activate some trails in V-structures just as it can deactivate direct segments of other trails.

To understand better the notion of active trails and d-separation see examples in Figure~\ref{fig:bn_d-separation}. In Figure~\ref{fig:bn_d-separation_a} you can see a Naïve Bayes model in which all feature variables $X_i$ and $X_j$ are conditionally independent given class variable $C$ because knowing the class variable deactivates all trails between $X_i$ and $X_j$.
In Figure~\ref{fig:bn_d-separation_b} we can see an activated V-structure R$\rightarrow$T$\leftarrow$A. When we know whether there is a traffic jam then, intuitively, an accident decreases probability of being it in a rush hour because an accident is sufficient to cause a traffic jam by itself. Similarly, if it is not a rush hour then knowing there is a traffic jam increases the probability of there being an accident. This is an example of inter-causal reasoning.

\begin{figure}[h]
\begin{center}
    \begin{subfigure}[b]{0.4\linewidth}
        \includegraphics[scale=0.4]{fig/bn-naive-bayes}
        \caption{$\forall i \neq j: X_i \perp X_j \mid C$}
        \label{fig:bn_d-separation_a}
    \end{subfigure}
    \qquad\qquad\qquad
    \begin{subfigure}[b]{0.4\linewidth}
        \includegraphics[scale=0.4]{fig/bn-d_sep}
        \caption{$R\not\perp A \mid T$ (active trail R-T-A-H)}
        \label{fig:bn_d-separation_b}
    \end{subfigure}
    \caption{Examples of d-separation and flow of influence.}
    \label{fig:bn_d-separation}
\end{center}
\end{figure}

It might be useful to explicitly point out what the notation $P(X_i \mid Parents(X_i))$ tells us in context of d-separation. It is a fact frequently used in mathematical derivations in context of BNs that, when given all parents $Parents(X_i)$ of a variable $X_i$, the variable is independent of all indirect parents of $X_i$ in the network.













\section{Inference in Bayesian networks}
There are several types of queries that might be asked in context of a Bayesian network. Most frequently, by inference in BNs is meant computing the posterior probability distribution for a set of query variables $\vars{X}$ given values $\vars{e}$ of evidence variables $\vars{E}$. Mathematically, the task is to compute the probability distribution $P(\vars{X} \mid \vars{e})$. Another type of query is so called \term{maximum a~posteriori} (abbreviated as MAP) that is finding $arg\ max_\vars{X} P(\vars{X} \mid \vars{e})$. MAP is basically used for finding out the most probable cause (concrete assignment of variables $\vars{X}$) for observation $\vars{e}$. A practical example could be getting the most probable word (sequence of letters) that corresponds to classifier output for a segmented picture containing that word. Although this is an example more frequently used in context of Markov networks.

Inference in a BN may be carried out in many ways depending on nature of the query and precision requirements. Exact inference is relatively straightforward in terms of mathematical description and naive algorithmic implementation but exhibits serious running-time disadvantage\,--\,exponential running time in the number of variables in the worst case. On the other hand, approximate inference methods allow us to answer queries more quickly but precision of the solution may be questionable, especially for very rare events.

\todo{maybe show types of queries\,--\,diagnostic, causal, intercausal, mixed?~\cite[p.~448]{russell_norvig_ed2}}

\subsection{Sum-product}
Probably the simplest method for computing a conditional probability query is called sum-product. The problem at hand is to compute conditional probability distribution $P(\vars{X} \mid \vars{e})$ where $\vars{X}$ is one or more variables, $\vars{e}$ is an assignment to evidence variables $\vars{E}$ and $\vars{Y}$ variables that are neither query nor evidence variables. The query is computed according to Bayes' theorem as follows:
\begin{equation*}
P(\vars{X} \mid \vars{e})
 = \frac{P(\vars{X}, \vars{e})} {P(\vars{e})}
 = \frac{\sum_\vars{Y} P(\vars{X}, \vars{y}, \vars{e})}{\sum_{\vars{X},\vars{Y}} P(\vars{x}, \vars{y}, \vars{e})}
\end{equation*}
The denominator is constant and since $P(\vars{X} \mid \vars{e})$ has to be a probability distribution, we can simply omit the denominator and in the end normalize numerator by some constant $\alpha$. Hence we can write
\begin{equation*}
P(\vars{X} \mid \vars{e})
 = \alpha \sum_\vars{Y} P(\vars{X}, \vars{y}, \vars{e})
\end{equation*}
Computation of this expression using the sum-product method means performing four steps:
\begin{enumerate}
	\item reducing all factors in the Bayesian network by evidence $\vars{e}$,
	\item multiplying reduced factors all together producing single joint factor $P(\vars{X},\vars{Y},\vars{e})$ which is not a probability distribution because, in general, all values of the factor don't sum to one,
	\item marginalizing over the variables $\vars{Y}$ (non-query and non-evidence variables) and finally
	\item renormalizing the resulting factor, obtaining the joint probability distribution $P(\vars{X},\vars{e})$.
\end{enumerate}

Every item of the sum in numerator, ie. probability of every possible assignment to variables $\vars{Y}$, can be written according to the joint probability distribution represented by a~BN (definition~\eqref{eq:bn_joint}) as a~product of conditional probabilities of all variables in given BN. This explains the name of this inference method\,--\,we effectively compute many products of conditional probabilities and sum over variables $\vars{Y}$.

Sum-product inference algorithm has, by its nature, exponential running time in the number of variables because it effectively generates the whole joint probability distribution encoded by a given Bayesian network and the size of a table representing any joint probability distribution has been earlier shown to be exponential in the number of variables. Because of this quality, the sum-product method is suitable only for inference in considerably small networks.

\begin{comment}
\uncertain{
Formally, exact number of operations carried out in the nominator sum during the sum-product inference can be determined as follows. Let $m$ be the number of all variables, let $n$~be the number of non-query and non-evidence variables $\vars{Y}$ and let $k$~be the number of possible assignments to a variable. The numerator summation unrolls to $k^n$ items, each item being a product of all $m$ factors which means $k^n (m-1)$ multiplications and $k^n - 1$ additions. Therefore the overall running time is roughly $O(m k^n)$.}
\end{comment}


\subsection{Variable elimination}
Variable elimination algorithm can be seen as a somewhat smarter implementation of the sum-product algorithm explained above. Again, we answer the given query by multiplying all factors of the BN and summing out $\vars{Y}$ variables. The innovative ideas behind variable elimination are:
\begin{itemize}
	\item Suppose we sum over many variables in a product of factors, say one of these variables is $V$. Then factors whose scopes don't contain $V$ are irrelevant for the summation over~$V$ and hence these factors can be factored out in front of the summation over~$V$. This way we can push all summations as far to the right as possible, so that each summation is done only over product of factors containing the variable $V$ being summed out. What is the benefit for us? It can be shown~\cite{pgm} that running time of variable elimination depends on the size of the largest immediate factor during the summing-out process. When we sum only over product of factors containing variable $V$, the resulting immediate factor is the smallest possible. Because problem of determining the optimal order of elimination is NP-hard, greedy heuristics are usually used instead~\cite{pgm}.
	\item By definition of a conditional probability distribution, it holds for any instantiation of parent variables that $\sum_V P(v \mid Parents(V)) = 1$. So, when computing posterior probability distribution $P(\vars{X} \mid \vars{e})$, any node (factor) $V$ that is not an ancestor of a~query or evidence variable can be omitted because, thanks to the order of elimination of variables, the term $\sum_V P(v \mid Parents(V))$ will be the rightmost summation (the innermost). So summing out $V$ is equivalent to totally excluding variable $V$ from the BN. Implementation can be recursively done in the way of eliminating all leaf nodes that are not in $\vars{X} \cup \vars{E}$ and performing the same operation for as long as some node gets removed~\cite[p.~510]{russell_norvig_ed2}.
\end{itemize}

%\todo{řeči kolem, algoritmus, časová složitost, kliky}

Running time of the variable elimination algorithm in polytrees is $O(n)$~\cite[p.~510]{russell_norvig_ed2}, therefore it is a good method for answering individual queries $P(X \mid \vars{e})$ where $X$ is a single variable. Analogically, we can effectively compute probability distribution for small number of query variables $\vars{X}$ by computing individual distributions $P(X_i \mid \vars{e})$ for all $X_i \in \vars{X}$ and returning $P(\vars{X} \mid \vars{e}) = \prod_i P(X_i \mid \vars{e})$.

Running time in multiply connected networks is exponential in general but it can be coped with by clustering algorithms that transform multiply connected network into a~polytree which can be processed in linear time.

\subsection{Belief propagation}
Belief propagation~\cite{pgm} is an approximate inference algorithm from the family of so called \term{message passing algorithms}. The main idea is that nodes in the BN exchange information about their believes (probability distributions affected by evidence) and the whole network converges to some solution close to true posterior probability. As methods from this family are far from trivial and they are not the aim of this thesis, we will not pay deeper attention to them.
\begin{comment}
\note{Cluster graphs and \term{running intersection property}: Nodes $C_i \subseteq \lbrace X_1, \dots, X_n \rbrace$ and sepsets $S_{i,j} \subseteq C_i \cup C_j$ such that for each factor $\phi$ exists $C_i$: $scope(\phi) \subseteq C_i$.
For each variable $X$ the nodes $C_i$ and sepsets containing $X$ form a tree (ie. no cycle and single unbroken component)\,--\,cycle would mean that a node would get information about variable $X$ twice and the probabilities would go up and up. If some node with $X$ would be isolated from others, it would not get the belief updates. Bethe cluster automatically satisfies the running intersection property.}
\end{comment}


\subsection{Sampling methods}
Monte Carlo methods (or particle methods) are stochastic methods of inference based on sampling the probability distribution induced by a BN. There are three main sampling methods: \term{direct sampling}, \term{rejection sampling} and \term{likelihood sampling}. All these methods basically generate a sufficient number of independent samples and then compute simple statistics over these samples. In general, relative precision of Monte Carlo methods is proportional to $1/\sqrt{N}$, where $N$ is the number of samples.

\subsubsection{Direct sampling}
Direct sampling is a method for computing unconditional probability distribution $P(\vars{X})$. It produces a number of samples, ie. of concrete events, according to the probability distribution induced by the given BN, and then for every assignment $\vars{x}$ computes its probability as $P(\vars{x}) = N_\vars{x} / N_{all}$, where $N_\vars{x}$ is the number of samples in which variables $\vars{X}$ have the values $\vars{x}$ and $N_{all}$ is the number of all samples generated.

A single sample is generated as follows. First randomly assign values to variables with no parents according to their probability distributions. Then choose a variable $V$ such that all of its parents have already been instantiated and randomly assign a value to $V$ according to the probability distribution $P(V \mid Parents(V))$ and according to the concrete values of its parents in current sample. Repeat this step until all variables have been instantiated, thereby obtaining a~sample. The process can easily be done if we first compute topological sort of the BN and then sample variables in ascending order.

It can be shown~\cite[p.~491]{pgm} that to obtain an estimate with error bounded by $\epsilon$ with probability at least $1-\delta$ we need to generate $M$ samples:
\begin{equation*}%\label{eq:sampling_accuracy}
M \geq \frac{\ln(2 / \delta)}{2 \epsilon ^ 2}
\end{equation*}
Problem is that for a very unlikely event we may not generate a single sample and therefore the obtained probability distribution would indicate that this event is impossible (its probability equals to zero). Still it would be a sound result within the error estimate $(\epsilon, \delta)$.

\subsubsection{Rejection sampling}
Direct sampling presented earlier doesn't allow for any evidence. Rejection sampling could be viewed as a simple extension of direct sampling for computing posterior probability distribution $P(\vars{X} \mid \vars{e})$. The idea is to exclude samples inconsistent with evidence $\vars{e}$ meaning that when an evidence variable is instantiated during the production of a sample, the sample is discarded unless the randomly assigned value corresponds with the observed value. Then $P(\vars{x} \mid \vars{e}) = N_{\vars{x},\vars{e}} / N_{\vars{e}}$. This simple approach bears the disadvantage that if the observed evidence is very unlikely then many samples get discarded and hence a lot of computational time is wasted because rejected samples don't contribute to the final probability distribution. Unfortunately, when considering somewhat uniform distribution, the probability $P(\vars{e})$ decreases exponentially with the number of observed variables (eg. with symptoms of a patient) and by the same rationale the number of samples that are not rejected decreases by the same amount.

\subsubsection{Likelihood weighting}
Rejection sampling described earlier can theoretically be used for answering queries of the form $P(\vars{X} \mid \vars{e})$ but the number of rejected samples may be unbearable in practice. Likelihood weighting method copes with this problem by forcing every sample to be consistent with observed evidence. Then, of course, not every sample is equally likely, so we cannot determine $P(\vars{x} \mid \vars{e})$ by simply dividing number of samples $N_{\vars{x},\vars{e}}$ by $N_\vars{e}$. For each sample $\vars{x},\vars{y},\vars{e}$ we need additional information which is the probability of assigning values $\vars{e}$ to evidence variables given its parents~\cite[p.~514]{russell_norvig_ed2}. Formally written, weight of a sample $\vars{x},\vars{y},\vars{e}$ is $w_{\vars{x},\vars{y},\vars{e}} = P(\vars{e} \mid Parents(\vars{E}))$.

The sampling algorithm needs to be changed in the following way. When generating a~new sample, we set weight of the current sample to 1. Then, for a non-evidence variable we proceed as before\,--\,randomly assign a value according to the probability distribution of that variable and according to values assigned to its parents. When we encounter an evidence variable $E_i$, we set it to value $e_i$ according to the evidence $\vars{e}$ and multiply weight of the current sample by $P(e_i \mid Parents(E_i))$. The final probability distribution is computed as follows:

\begin{equation*}
    P(\vars{x} \mid \vars{e})
    = \frac
        {w_{\vars{x},\vars{e}} \cdot N_{\vars{x},\vars{e}}}
        {\sum_\vars{X} (w_{\vars{x},\vars{e}} \cdot N_{\vars{x},\vars{e}})}
\end{equation*}

I believe that the sampling process can furthermore be accelerated by omitting variables $\vars{Y'}$ that satisfy the following two conditions: (1) $\vars{Y'} \cap (\vars{X} \cup \vars{E}) = \emptyset$, (2) no direct or indirect child of any variable from $\vars{Y'}$ is in $\vars{X} \cup \vars{E}$. Rationale behind this is the same as in the variable elimination algorithm\,--\,when computing the final probability distribution, we effectively sum out variables $\vars{Y'}$ and it is irrelevant what values they were assigned because they contribute to the same buckets $N_{\vars{x},\vars{e}}$ and don't affect the weight. This observation is applicable also to direct and rejection sampling.

An important drawback of importance sampling is that it doesn't account well for evidence in leaf nodes or near to them. This is because in that case we effectively sample the prior probability distribution and finally assign a weight to the generated sample by evidence but the sampling process is most of the time unaffected by the evidence and virtually only weights take evidence into account. So, for a very rare evidence (eg. for some rare set of symptoms) all of the generated samples might have very small weight and, in case of medical diagnosis, no sample representing the "real cause" of observed evidence might be generated. Once again, this is because we sample prior probability distribution rather than posterior and these two distributions may be very different~\cite[p.~503]{pgm}.

\subsection{Markov Chain Monte Carlo}
The likelihood weighting method presented earlier doesn't account well for evidences in or near leaf nodes, ie. so called evidential reasoning. Markov Chain Monte Carlo (MCMC) is also a stochastic method that generates samples but rather than generating each sample completely from scratch it modifies the last sample by resampling one of the non-evidence variables. This way, the information about all evidence variables propagates through the network.

To explain how the MCMC algorithm works we first need to introduce \term{Markov blanket} of a~variable $X$, denoted $MB(X)$. The Markov blanket of $X$ is a minimal set of variables such that $X$ is conditionally independent of all other variables given $MB(X)$. It is fairly obvious that the Markov blanket includes variables $Parents(X)$ and direct children $\vars{C}$ of $X$ because there is a direct connection between them and $X$. Furthermore, $MB(X)$ also needs to include parents of $\vars{C}$ because observing any of the children $C_i$ activates a V-structure and $X$ becomes conditionally dependent on $Parents(C_i)$ given $C_i$.

The MCMC algorithm~\cite[p.~516]{russell_norvig_ed2} starts by producing one sample consistent with the evidence, eg. by one iteration of likelihood weighting with the weight discarded. Then we repeat the following: For each non-evidence variable $Y$ we resample this variable from current distribution $P(Y \mid MB(Y))$ producing a new sample with value of variable $Y$ potentially changed. For the new sample we increase the corresponding counter $N_{\vars{x},\vars{e}}$ and proceed with resampling another variable. The distribution $P(Y \mid MB(Y))$ can be obtained by computing $P(y \mid MB(Y))$ for every $y$ as follows:
\begin{equation*}
    P(y \mid MB(Y)) = \alpha \cdot P(y \mid Parents(Y)) \prod_{i} P(c_i \mid Parents(C_i))
\end{equation*}
where $\alpha$ is a normalizing constant. Note that $MB(\cdot)$ and $Parents(\cdot)$ in this context denote concrete instantiation of respective variables in the current sample.

Intuition behind the MCMC algorithm is that the sampling process will reach a dynamic equilibrium in which time spent with each instantiation of non-evidence variables (ie. the counter of samples $N_{\vars{x},\vars{e}}$) is proportional to the probability of this instantiation. More formally, MCMC is based on state space induced by a BN represented by a Markov model~\cite[p.~516]{russell_norvig_ed2} but this theory is not necessary for understanding the MCMC inference method.

%\note{pgm 541+ has good notes of other papers} % SP

\begin{comment}
$\pi(x)$ is the stationary distribution (ustálený)

works for regular Markov chains ($\exists k \forall x, x':$ z $x$ do $x'$ se lze dostatat přesně v $k$ krocích s nenulovou pstí)
\end{comment}












\section{Model learning}
So far, we have been reasoning about Bayesian networks that were already given to us, so that both the structure of the BN and the CPDs associated with nodes were known. Now we are going to examine the problem of creating a Bayesian network so that the probability distribution it induces somehow corresponds to the real probability distribution of the target domain.

Basically, there are two approaches to creating a BN. First option is to cooperate with an expert of target domain who can make correct dependency and independency assumptions and provide us with conditional probability distributions, ie. with CPDs to all nodes. The other approach is to use automated techniques for creating models based on a big dataset. The dataset can be viewed as a set of samples of the target probability distribution $P*$ which we attempt to reconstruct. The aim is to create a model $\tilde{\mathcal{M}}$ such that the probability distribution $P_{\tilde{\mathcal{M}}}$ induced by $\tilde{\mathcal{M}}$ is "very close" to the original distribution $P*$.

Complete construction of a BN through cooperation with an expert is problematic because, for a non-trivial BN, the task often requires significant time (several months~\cite{pgm}), the expert might not correctly capture CPDs, especially for nodes with large number of parents and furthermore there might not even be an expert of the target domain at all. On the other hand, automated techniques of model construction are constrained by limited computational power and more importantly by the size of the supplied dataset. As will be shown later, we encounter classic problem of overfitting and bias-variance trade-off present in the whole artificial intelligence and machine learning. In practice we often combine these two approaches in the way that an expert defines structure (all variables and their dependencies) and an automated process determines CPDs by supplied dataset.

%\todo{maybe include general metrics?} % SP

\section{Parameter estimation}
Goal of parameter estimation is to supply CPDs to a BN whose structure is already known. In order for the estimation to be reasonably correct, we need to have sufficiently large dataset wrt. complexity of the BN structure.


\subsection{Maximum likelihood estimation}
Maximum likelihood estimation views the dataset $\mathcal{D}$ as a set of independent samples $x_1, \dots, x_m$ taken from a~parametrized probability distribution with parameter $\Theta$. The parameter $\Theta$ can be viewed as a vector of entries of all CPDs if the probability distribution was represented by a BN. Core of the maximum likelihood estimation is to choose $\Theta$ in such a way that the probability of obtaining samples $x_1, \dots, x_m$ from the parametrized distribution is maximal. Formally $\Theta = \arg \max P(\mathcal{D} \mid \Theta)$ where $P(\mathcal{D} \mid \Theta)$ is called \term{likelihood function}.

Let's inspect a simple example of $m$ coin tosses $x_1, \dots, x_m$ with a biased coin for which $P(X = heads) = \theta$ (inspired by~\cite{pgm}). Let's suppose we get $H$ times heads and $T$ times tails. Then we can write $P(x_1,\dots,x_m \mid \theta) = \theta^H (1 - \theta)^T$ because the coin tosses are independent given $\theta$. The task of maximizing the expression $\theta^H (1 - \theta)^T$ is equivalent to maximizing its logarithm $H \cdot \ln(\theta) + T \cdot \ln(1 - \theta)$. The equation $\frac{\partial}{\partial\theta} \ H \cdot \ln(\theta) + T \cdot \ln(1 - \theta) = 0$ yields global maximum $\theta = H / (H + T)$ which is a fairly intuitive conclusion\,--\,number of times we got heads divided by the number of all tosses. Similar formula can be obtained for a~general multinomial distribution.

Now suppose we want to compute probability distribution $P(X \mid Parents(X))$ for some node $X$ according to our dataset, ie. to compute the CPD of that node.
Maximum likelihood estimation is, as demonstrated earlier, an intuitive approach when we partition the dataset to disjoint subsets, each for a concrete instantiation of variables $\lbrace X \rbrace \cup Parents(X)$. Then CPD entry $P(X=x_i \mid Parents(X) = \vars{p_i})$ is computed as the ratio $N_{x_i,\vars{p_i}} / N_{\vars{p_i}}$. Potential problem with this approach is that the number of subsets grows exponentially with the number of parents and hence the estimated CPD looses precision. This exponential explosion of possible instantiations is called \term{fragmentation} and it is one of the main problems of learning BNs from data. Because of fragmentation a perfect model capturing all dependencies between variables might be outperformed by a simpler and wrong model just because we didn't have sufficient amount of data to accurately compute CPDs for the more complicated structure\footnote{Such observation has often been made, for example, with the Naïve Bayes model which assumes that any two effect variables are independent given the cause variables. Such assumption is seldom justified, nevertheless Naïve Bayes models have proved themselves to perform well.}~\cite{pgm}. This is a~typical AI problem of overfitting. In extreme cases $N_{x_i,\vars{p_i}}$ could be zero which is in most cases very wrong. This can be prevented by applying the Laplace's correction used in context of Naïve Bayes classifier.


\subsection{Bayesian estimation}
An important drawback of the maximum likelihood estimation presented earlier is that it doesn't really account for the size of the dataset\,--\,small dataset may not have enough samples for every instantiation of every variable and its parents and the dataset might be noisy. The key idea of Bayesian estimation is to view the parameters themselves (ie. CPDs) as random variables with some prior distribution and then, according to the supplied dataset, compute the posterior distribution over parameters which will be our estimated CPDs. So, parameter learning is in this case a type of inference.
More formally, we define a~prior distribution $P(\Theta)$ over parameters $\Theta$ with some degree of strength of this initial distribution and then, using the Bayes' rule, compute the posterior probability distribution $P(\Theta \mid \mathcal{D}) \propto P(\mathcal{D},\Theta) P(\Theta)$ as we get more empirical data. This way the Bayesian estimation can, for example, distinguish between rolling a~six three times out of eight throws, which may be accounted just to statistical noise, and rolling a six 3\,000 times out of 8\,000 throws. It is clear that these two datasets tell us something different about the die, although probability of rolling a six, according to the maximum likelihood estimation, is $3/8$ in both cases.

The exact mathematical derivation~\cite[p.~733]{pgm} of Bayesian parameter estimation formulas is based on \term{Dirichlet distribution}$(\alpha_1,\dots,\alpha_k)$. The derivation is not trivial and also is not needed further in this thesis, so we jump straight to the practical conclusions and interpretations. For a~given dataset $\mathcal{D}$ and hyperparameters $(\alpha_1, \dots, \alpha_k)$ the probability of variable $X$ having value $x_i$ is given as follows:

\begin{equation*}
    \begin{array}{rcl}
    P(X = x_i \mid \mathcal{D}) &
     = &
     \displaystyle\frac
        {\alpha_i + N_{x_i}}
        {\sum_j (\alpha_j + N_{x_j})}\\
        & & \\
    P(X = x_i \mid Parents(X) = \vars{p_i}, \mathcal{D}) &
     = &
     \displaystyle\frac
        {\alpha_{x_i \mid \vars{p_i}} + N_{x_i, \vars{p_i}}}
        {\sum_j (\alpha_{x_j \mid \vars{p_i}} + N_{x_j, \vars{p_i}})}
    \end{array}
\end{equation*}
where a hyperparameter $\alpha_i$ can be viewed as count of imaginary samples $x_i$ (also called \term{pseudo-samples}), similarly for $\alpha_{x_i \mid \vars{p_i}}$. Hyperparameters define both:
\begin{enumerate}
	\item The prior distribution $P(\Theta)$\,--\,initial CPD values defined by ratios $\alpha_i / \sum_j \alpha_j$.
	\item The confidence we have in the prior distribution\,--\,the total sum $\sum_j \alpha_j$ is called \term{equivalent sample size} and tells us how many samples it takes to deviate from the prior distribution.
\end{enumerate}
We have already encountered two special cases of hyperparameters\,--\,$(0,\dots,0)$ is the pure maximum likelihood estimation when we compute the CPDs based just on the dataset $\mathcal{D}$; hyperparameters $(1,\dots,1)$ correspond the maximum likelihood estimation with Laplace's correction.
It is clear that the maximum likelihood estimation and the Bayesian estimation are asymptotically the same for large datasets. However, Bayesian estimation generalizes better with sparse datasets and exhibits lower sensitivity to noise in the data~\cite[p.~749]{pgm}.

\medskip

Parameter learning methods explained so far deal strictly with table CPDs and assume that parameters $\Theta$ of the BN are independent. More advanced methods of parameters learning include learning structured probability distributions (eg. tree-based) and dependent or shared parameters~\cite{pgm}.

\begin{comment}
\begin{itemize}
	\item Familiar vs. unfamiliar setting (coin tossing vs. two teams playing)
	\item anything uncertain is viewed as random variable that is updated over time as data is acquired
	\item learning as a special type of inference (prior is what we expect the distribution to be $P(\Theta)$ and posterior is $P(\Theta \mid \mathcal{D}) \propto P(\Theta) \prod_{X_i \in \mathcal{D}} P(X_i \mid \Theta)$)
	\item better for sparse datasets (better generalization)
	\item no need for Laplace correction (somewhat implicit by the initial $P(\Theta)$).
	\item $\alpha_i$ correspond to seeing $\alpha_i$ occurrences of $x_i$ a priori (imaginary samples)
	\item use\,--\,plot learning curves? try alphas on logarithmic scale?
\end{itemize}
\end{comment}











\section{Structure learning}
So far we have seen how to compute CPDs for a given graph structure of a BN based on some dataset. Learning the structure itself can be useful for a number of reasons. For example, we want to create an accurate model of certain domain to be able to perform inference later (medical diagnosis, general classification etc.). Other application could be in the field of knowledge discovery when we are interested in knowing the causal dependencies between random variables (protein-signaling networks~\cite{sachs05}, analysis of critical nodes for traffic congestion etc.).

Learning structure of a BN is a complicated task. One of the problems is to pick a~good trade-off between high bias (restricting complexity of the graph structure) and high variance (allowing more dependencies to get a better fit for training data). As we have already discussed, with a small dataset we may actually benefit by having a simpler structure. On the other hand, with a large dataset we don't want to restrict our hypothesis space too much because the dataset is sufficient to learn higher number of parameters with good accuracy.

In this chapter we are going to discuss \term{score-based} methods of structure learning\,--\,likelihood score and Bayesian score. Structure learning is basically a discrete optimization task and for such tasks there are many well known approaches\,--\,simulated annealing, genetic algorithms, evolutionary programming and many others. As discrete optimization methods are not the key topic of this thesis, we will work with simple hill climbing heuristics instead. Nevertheless a common requirement for using any optimization technique is a mechanism that evaluates quality of a candidate solution. Such role play the score functions which we will discuss in detail.
Other than score-based approach there also is constraint-based approach which will not be further examined for its limitations. % SP


\subsection{Optimization algorithm}
In context of Bayesian networks, the technique most frequently used is simple hill climbing~\cite{pgm} which works as follows. We have an initial graph structure with fixed set of variables. The initial structure may be empty, it may be the best-scoring tree/forrest or some network capturing our prior knowledge and believes regarding the target domain. Then we repeatedly try all possibilities of adding a new edge, flipping direction or deletion of an existing edge and we evaluate the new structure using a predefined metric. We accept the change with the best gain and repeat these actions until the solution improves.
 


\subsection{Likelihood score}
The likelihood score has information-theoretic foundations and basically quantifies how well a given network structure matches our dataset. We assume that for a given structure $\mathcal{G}$ the parameters $\Theta$ are learnt using the maximum likelihood estimation, so the likelihood score really evaluates the hypothesis $(\mathcal{G}, \Theta)$.

Again, the goal is to maximize probability of the data given a hypothesis. Let's suppose we have a dataset $\mathcal{D} = \lbrace \xi_1, \dots, \xi_m \rbrace$ and let's examine network $\mathcal{G}_1$ with two independent variables $X$ and $Y$ and network $\mathcal{G}_2$ with structure $X \rightarrow Y$. Then their likelihood scores are computed as follows:
\begin{eqnarray*}
    score_L(\mathcal{G}_1 : \mathcal{D}) & = & \sum_{i=1}^m \Bigl(\log \hat P(x^{(i)}) + \log \hat P(y^{(i)})\Bigr)\\
    score_L(\mathcal{G}_2 : \mathcal{D}) & = & \sum_{i=1}^m \Bigl(\log \hat P(x^{(i)}) + \log \hat P(y^{(i)} \mid x^{(i)})\Bigr)
\end{eqnarray*}
where $score_L(\mathcal{G}_1 : \mathcal{D})$ denotes the likelihood score of structure $\mathcal{G}_1$ with dataset $\mathcal{D}$, $x^{(i)}$ is value of variable $X$ in example $\xi_i$ and $\hat P$ denotes the \term{empirical distribution}. Empirical distribution is computed from the dataset $\mathcal{D}$ according to the maximum likelihood principle, eg. $\hat P(x_i) = N_{x_i} / N$ or $\hat P(x_i \mid y_j) = N_{x_i,y_j} / N_{y_j}$.

Now let's examine the difference between having an edge between variables $X$ and $Y$ or not. We obtain the following result (for complete derivation see~\cite[p.~791]{pgm}):
\begin{eqnarray*}
   score_L(\mathcal{G}_2 : \mathcal{D}) - score_L(\mathcal{G}_1 : \mathcal{D}) %& = & \sum_{i=1}^m \log \hat P(y[i] \mid x[i]) - \sum_{i=1}^m \log \hat P(y[i]) \\
     %& = & \sum_{X,Y} N_{x,y} \log \hat P(y \mid x) - \sum_{Y} N_y \log \hat P(y) \\
     %& = & \sum_{X,Y} N \cdot \hat P(x,y) \log \hat P(y \mid x) - \sum_{Y} N \cdot \hat P(y) \log \hat P(y) \\
     %& = & \sum_{X,Y} N \cdot \hat P(x,y) \log \hat P(y \mid x) - \sum_{X, Y} N \cdot \hat P(x, y) \log \hat P(y) \\
     %& = & N \sum_{X,Y} \hat P(x,y) \log \frac{\hat P(y \mid x)}{\hat P(y)} \\
     & = & N \sum_{X,Y} \hat P(x,y) \log \frac{\hat P(x, y)}{\hat P(x) \hat P(y)} \\
     & = & N \cdot I_{\hat P}(X; Y)
\end{eqnarray*}
%The first step is to change the logic of the summation from "over the dataset $\xi_1,\dots,\xi_m$" to "over possible instantiations of $X,Y$". Then we express the counts $N_{x,y},N_y$ using size of the dataset $N$ and their empirical probabilities of respective instantiations. After that we can extend the second summation from just over $Y$ to over $X,Y$. The final step is merging the two sums and logarithms.
The term $I_{\hat P}(X; Y)$ is called \term{mutual information} between $X$ and $Y$ and expresses the average distance between the joint distribution $P(X,Y)$ when the variables are dependent to the distribution given as product of marginal distributions $P(X)$ and $P(Y)$ when the variables are independent. It can be proved (for details see~\cite[p.~792]{pgm}) that the overall likelihood score decomposes over a general graph $\mathcal{G}$ as follows:
\begin{equation}
    score_L(\mathcal{G} : \mathcal{D}) = N \!\!\!\!\!\! \sum_{X_i \in Nodes} \!\!\!\!\!\! I_{\hat P}(X_i;Parents(X_i)) - N \!\!\!\!\!\! \sum_{X_i \in Nodes} \!\!\!\!\!\! H_{\hat P}(X_i)
\end{equation}
where $H_{\hat P}(\cdot)$ is entropy of an individual variable which is a constant relative to the structure of $\mathcal{G}$. So, in order to compare two network structures we need to consider only the values of the first sum.

\medskip
The difference of likelihood scores between a superstructure with more edges and its substructure is always non-negative and, in fact, is equal to zero if and only if the two variables $X,Y$ in the dataset $\mathcal{D}$ appear to be perfectly independent which is due to statistical noise almost never true. Therefore the likelihood score itself almost always suggests the greedy heuristics to add an edge which would eventually lead to a fully connected network. In other words, the likelihood score is very prone to overfitting. This problem can be addressed by thresholding of the score increase or by restraining complexity of the network (defining maximal number of parents or maximal number of overall network parameters). Another approach is to account for network complexity in the scoring function itself, thus imposing a penalty on complicated structures. The latter is exactly what the BIC score does.



\subsection{BIC score}
The likelihood score discussed earlier never favors a simpler structure over a more complex one. We will discuss a variant of Bayesian score called \term{BIC score} which is, in the end, just the likelihood score extended by a penalty term although theoretical foundations and mathematical derivations leading to the final formulas are entirely different.

%\note{pgm 798 gives nice understanding of the use of gamma function}

The BIC score takes into account both network complexity as well as the size of the dataset and combines these two pieces of information in such a way that with a small dataset the BIC score tends to keep the structure simple and allows only for the strongest dependencies to be be reflected in the network. As the dataset gets larger, the BIC score allows also for a more complicated structure that encodes also weaker dependencies.

The BIC score is given as follows (for complete derivation see~\cite[p.~794]{pgm}):
\begin{equation}
    score_{BIC}(\mathcal{G} : \mathcal{D}) = N \!\!\!\!\!\! \sum_{X_i \in Nodes} \!\!\!\!\!\! I_{\hat P}(X_i;Parents(X_i)) - N \!\!\!\!\!\! \sum_{X_i \in Nodes} \!\!\!\!\!\! H_{\hat P}(X_i) - \frac{\log N}{2} Dim[\mathcal{G}]
\end{equation}
where $Dim[\mathcal{G}]$ is dimension of the network (number of its parameters). Notice that the two sums are the likelihood score $score_{L}(\mathcal{G} : \mathcal{D})$. We can see that the BIC score increases linearly in $N$ with dependent variables being connected (the first term) and decreases logarithmically in $N$ with the network complexity (the third term). Thus for a sparse dataset only the strong dependencies will be present in the final network, whereas for a~large dataset the penalization increases at slower rate allowing the network to have a~more complicated structure including weaker dependencies.

Note that the BIC score decomposes over the graph $\mathcal{G}$, so when we want to evaluate some structural change, we only need to consider the score difference of nodes affected by this change, so called \term{delta score}. This observation is crucial for an effective implementation of structure learning based on local optimization of the score function. 



\subsection{Bayesian score}
Bayesian score for a graph structure is yet another application of the Bayesian principle encountered in context of parameter estimation\,--\,whatever we are uncertain about should be modeled as a random variable. To state the idea formally, graph structure $\mathcal{G}$ is a~random variable for which holds $P(\mathcal{G} \mid \mathcal{D}) = P(\mathcal{D} \mid \mathcal{G}) P(\mathcal{G}) / P(\mathcal{D})$. The denominator is independent of the network structure and parameters, so we can safely consider just the numerator. Further we will consider logarithm of the numerator which is perfectly legal because logarithm is a~monotone function. By applying the logarithm we obtain the Bayesian score for structure $\mathcal{G}$ and data $\mathcal{D}$ as:
\begin{equation}\label{eq:bayesian_score_general}
    score_B(\mathcal{G} : \mathcal{D}) = \log P(\mathcal{D} \mid \mathcal{G}) + \log P(\mathcal{G})
\end{equation}
The term $P(\mathcal{D} \mid \mathcal{G})$ in equation~\eqref{eq:bayesian_score_general} is a marginal distribution (because all possible parameter settings $\Theta$ are marginalized out) defined as follows:
\begin{equation}\label{eq:bayesian_score_marginal}
    P(\mathcal{D} \mid \mathcal{G})
    =
    \int_{\Theta} P(\mathcal{D} \mid \mathcal{G}, \Theta) P(\Theta \mid \mathcal{G}) \ d \Theta
\end{equation}
The integral expression can be interpreted as computing the average probability of $\mathcal{D}$ given $\mathcal{G}$ weighted by probabilities of possible parameters settings $\Theta$. So, the Bayesian estimation is more conservative when compared to the BIC score which considers only parameters $\Theta$ computed by the maximum likelihood estimation. Therefore Bayesian score is less prone to overfitting.

The integral in equation~\eqref{eq:bayesian_score_marginal} is very abstract. Fortunately, for a BN with multinomial variables, whose prior distribution is a Dirichlet distribution with hyperparameters $(\alpha_1, \dots, \alpha_n)$, the expression can be written in closed form as follows~\cite[p.~796]{pgm}:
\begin{equation*}
    P(\mathcal{D} \mid \mathcal{G})
    =
     \prod_{X \in Nodes}
             \Bigl[
                \prod_{\vars{p} \in Val(Parents(X))}
                   \Bigl(
                      \frac{\Gamma(\alpha_{X \mid \vars{p}})}{\Gamma(\alpha_{X \mid \vars{p}} + N_{\vars{p}})}
                      \prod_{x \in Val(X)} \frac{\Gamma(\alpha_{x \mid \vars{p}} + N_{x, \vars{p}})}{\Gamma(\alpha_{x \mid \vars{p}})}
                   \Bigr)
             \Bigr]
\end{equation*}
where $\Gamma$ is the \term{gamma function} which is a continuous generalization of factorial. Gamma function needs to be used because, in general, hyperparameters of a Dirichlet distribution don't necessarily have to be integers.
\begin{comment}
The first term $\log P(\mathcal{D} \mid \mathcal{G})$ of equation~\eqref{eq:bayesian_score_general} can be interpreted in many ways. Suppose we have a multinomial distribution over variable $X$ where $Val(X) = \lbrace x_1,\dots,x_k\rbrace$ and suppose that the prior distribution over $X$ is a Dirichlet distribution with hyperparameters $(\alpha_1, \dots, \alpha_n)$. One simple and intuitive way to derive a useful representation for $P(\mathcal{D} \mid \mathcal{G})$ is to use the chain rule and combinatorial derivations as follows~\cite[p.~796]{pgm}:
\begin{eqnarray*}
    P(\mathcal{D} \mid \mathcal{G}) & = & P(\xi_1, \dots, \xi_m \mid \mathcal{G}) \\
    & = & P(\xi_1 \mid \mathcal{G})
          \cdot
          P(\xi_2 \mid \xi_1, \mathcal{G})
          \cdot
          P(\xi_3 \mid \xi_1, \xi_2, \mathcal{G})
          \dotsm
          P(\xi_m \mid \xi_1, \xi_2,\dots,xi_{m-1}, \mathcal{G}) \\
    & = & \frac
             {
              \alpha_{x_1} \dotsm (\alpha_{x_1} + N_{x_1} - 1)
              \ \cdot \ 
              \alpha_{x_2} \dotsm (\alpha_{x_2} + N_{x_2} - 1)
              \ \cdot \ 
              \dotsm
              \ \cdot \ 
              \alpha_{x_k} \dotsm (\alpha_{x_k} + N_{x_k} - 1)
             }
             {\alpha (\alpha + 1) (\alpha + 2) \dotsm (\alpha + N - 1)} \\
    & = & \prod_{X_i \in Nodes}
             \Bigl[
                \prod_{\vars{p_i} \in Val(Parents(X))}
                   \Bigl(
                      \frac{\Gamma(\alpha_{X_i \mid \vars{p_i}})}{\Gamma(\alpha_{X_i \mid \vars{p_i}} + N_{\vars{p_i}})}
                      \prod_{x \in Val(X_i)} \frac{\Gamma(\alpha_{x \mid \vars{p_i}} + N_{x, \vars{p_i}})}{\Gamma(\alpha_{x \mid \vars{p_i}})}
                   \Bigr)
             \Bigr]
\end{eqnarray*}
where $\Gamma$ is the \term{gamma function} which is a continuous generalization of factorial. Gamma function needs to be used because, in general, hyperparameters of Dirichlet distribution don't need to be integers.
\end{comment}

\medskip

The structure prior $P(\mathcal{G})$ in the equation~\eqref{eq:bayesian_score_general} allows us to penalize certain structures but its effect is rather minor, especially in asymptotic analysis~\cite[p.~804]{pgm}, because this term doesn't change with the number of samples. Most often we use a uniform prior or a prior that exponentially penalizes complexity of the structure which is useful for sparse datasets.

\medskip

To be able to use Bayesian scores we also need to define prior distribution over parameters $P(\Theta \mid \mathcal{G})$. The key problem is to represent the prior in some space efficient form because the naive approach would be to define a prior for every possible structure $\mathcal{G}$. A~simple approach is to use a fixed Dirichlet distribution $(\alpha',\dots,\alpha')$ which is, unfortunately, from its nature inconsistent in the sense that the equivalent sample size $\alpha = \sum \alpha'$ depends on the number of parents of a node. Another approach is to encode the prior distribution $P'$ by a BN and to infer the terms $\alpha_{x \mid \vars{p}} = \alpha \cdot P'(x, \vars{p})$ as they are needed. The latter option is called the \term{BDe prior}~\cite[p.~806]{pgm} and its main advantage is that we can use a single network to infer prior distribution for any structure $\mathcal{G}$.



\subsection{Learning specific structures}
We already know the necessary specifics of evaluating how well a graph structure matches our data. Now we will discuss specifics of learning two types of structures\,--\,trees/forests and general graphs. 

\subsubsection{Learning a tree-structured network}
Let a tree-structured network be any network such that every node has at most one parent. Then for a tree-structured network, the likelihood score or the BIC score don't distinguish orientations of the edges because in this situation is the mutual information for any combination of edge orientations and for any two variables exactly the same. Therefore we can for each pair of variables compute the difference of BIC score between the two situations when these two variables are directly connected and when not. Now, if the BIC score difference represents weight of an edge, we can compute the maximal spanning tree using Kruskal's algorithm or similar and finally remove edges with non-positive weights, thereby possibly obtaining a forest. The whole procedure is carried out in $O(n^2)$ time.

The best scoring forest is useful, for example, as a starting point for search of a general graph structure. Trees are also not prone to overfitting because the structure doesn't allow for a complicated hypothesis.

\subsubsection{Learning a general graph}
The search for a graph with general structure has already been characterized as an optimization task of maximizing score of the whole structure. We usually explore the space of all hypotheses using some greedy algorithm (best-first-search, hill climbing, tabu search etc.) but, of course, other more sophisticated optimization methods are applicable as well. The search starts with some initial structure which can be graph with no edges, the best scoring forest, random graph or structure capturing our prior knowledge and believes regarding the target domain. The search uses the following three basic operators: edge addition, edge removal and edge reversal. The problem of local maxima in the context of greedy algorithms is usually addressed by introducing a tabu list or by random restarts making a~number of random transformations regardless the score difference. Another problem that often arises is the problem of \term{plateaux} which means that structures with low edit distance often have almost the same or exactly the same score (reversing an edge in a tree etc.). A plateau effectively makes the search space locally "flat" in terms of the score function and the space search algorithm can't pick the right direction to go. It turns out that the problem of plateaux is also solvable by random restarts or by a tabu list~\cite[p.~815]{pgm}.

When considering computational complexity of greedy search, let's remember that the scoring functions are decomposable with the structure of the graph. So, in order to evaluate a structural change, we only need to consider change of scores of the nodes affected by this change and score of the rest of the network remains the same~\cite[p.~818]{pgm}. Furthermore, the state space exploration has local character because the structure changes only locally by applying the edge addition/removal/reversal operators. Therefore, in consequent search steps we often need to reexamine many structural changes again to pick the best one and caching of previously examined changes leads to a significant speedup~\cite[p.~819]{pgm}.
% SP pgm820 - data structures for caching

\begin{comment}
tree structures
\begin{itemize}
	\item tree has nice math
	\item sparse parameters (no overfit, for small datasets)
	\item direction don't matter (mutual information is the same because we have only one parent), so we compute edge weights for every two nodes and find a maximum-weight spanning tree (Kruskal algorithm etc.) in $O(n^2)$. Then remove zero weight edges for a forest.
	\item the algorithm doesn't determine direction of edges
\end{itemize}
general graphs
\begin{itemize}
	\item begin with random graph, empty, best tree, prior knowledge
	\item add/remove/reverse an edge
	\item greedy, best-first search, simulated annealing, \dots
\end{itemize}
\end{comment}




















\chapter{Implementation}
This chapter will present the program realization of this thesis. I will describe:
\begin{itemize}
	\item What data structures are used for representing factors/CPDs, network nodes and the overall Bayesian network.
	\item Algorithms needed for effective inference and learning including their modifications and tweaks. As the previous chapters have mostly been of mathematical nature, at this point it might be useful to explain solutions of some of the problems in a more algorithmic way.
	\item The overall design of the resulting application, a class diagram and description of single classes, their dependencies and responsibilities.
\end{itemize}
Extent of this chapter is expected to be around 10 pages.
























\chapter{Selected applications}
This chapter will present collection of selected applications suitable for Bayesian network learning. We will always examine the problem itself, reason why it is interesting, approach to its solution and the achieved results. At the time of writing the term project, candidate applications are the ones described in the rest of this chapter. Extent of this chapter is expected to be 10-15 pages.

\section{ICU alarm network (general model learning)}
The \term{ICU alarm network}\footnote{The ICU alarm network is, among others, freely available at The Hebrew University of Jerusalem \ignore{\url{http://www.bnlearn.com/bnrepository/}}\url{http://www.cs.huji.ac.il/site/labs/compbio/Repository/networks.html}.} (ICU stands for \term{Intensive care unit}) serves in the world of Bayesian networks as a benchmark for parameter and structure learning algorithms. The network itself has been hand-constructed and tuned in cooperation with the ICU personal. There are two types of goals: (a)~we attempt to learn parameters for a known structure, (b)~we attempt to learn both structure and parameters. Because the network is freely available, the usual course of action is to create an artificial dataset by sampling the original network, then performing the learning process and finally evaluating the obtained result by comparison with the original ICU network. 


\section{Crime prediction (knowledge discovery)}
We are given a dataset\footnote{The dataset \emph{Communities and crime} is available at \url{http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime}.} containing records for various communities across the United States. A single record contains features such as racial representation, income, family completeness, housing etc. and the number of violent crimes. The goal is to find a structure of a BN that will hopefully provide us with better insight into causal dependencies between features and that can potentially help us identify the root causes of crime.

Similar task has been previously inspected as a school project for the "Knowledge Discovery in Databases (2012/2013)" class at BUT FIT by me and Petr Beňas. We learned that transforming each continuous value to membership degrees to three fuzzy sets (low, medium, high) preserves variance of the data which might be useful because the data could be discretized and the learning process would be relatively simple. Knowledge discovery techniques used in the project did not include any probabilistic model.


\section{Spam filtering (document classification)}
For a given set of training e-mails, we need to preprocess the data and extract relevant features (keywords, sender domain, font color, numbers and currency symbols etc.) to form a feature vector. Some of the features may be hand-crafted, other might be automatically selected, for example by the highest mutual information between a feature $X_i$ and the class variable~$C$. Then we may learn (1) a Naïve Bayesian model, (2) an extension of the naive model which also allows for a limited degree of dependencies between features. Finally, we can analyze the increase in accuracy (if any) of the more complex and more expressive model.

The usefulness of Naïve Bayesian model for spam classification has been studied in~\cite{heckerman98_spam}.

\begin{comment}
\todo{
\begin{itemize}
	\item Medical diagnosis (from a big dataset of patient records)\,--\,structure and CPDs.
	\item Pedigrees (BUT structure is known).
	\item protein networks (how a protein influences another protein)\,--\,lecture "Learning General Graphs: Heuristic Search", dataset at \url{http://www.causality.inf.ethz.ch/repository.php}
\end{itemize}
}
\end{comment}








\chapter{Conclusion}
During the term project I focused on studying the theory of Bayesian networks, mainly from the books~\cite{pgm,russell_norvig_ed2}. As a supporting material I also attended an on-line course called Probabilistic Graphical Models at \url{http://www.coursera.org} taught by professor Daphne Koller at Stanford University.

I explained the fundamentals of Bayesian networks, described various methods of inference (exact, stochastic and message passing) and methods of model learning. I also focused on explaining strong points and limitations throughout this thesis. All techniques have been studied and presented in such a detail that is needed in order to successfully implement them and to understand their limitations.

\medskip

In the summer semester I am going to study the selected application cases in depth and provide a program realization. At first, I am going to attempt to reproduce results achieved by other authors and then possibly apply the presented techniques to other problems or to achieve better results than have been presented. If needed, I will also study specific variants of model learning (especially from~\cite{heckerman96} and~\cite{buntine94}) and stochastic inference (especially from~\cite{neal93}). Furthermore, the book~\cite{pgm} provides an extensive list of relevant literature for every topic presented in this thesis.


\begin{comment}
What I did:
\begin{itemize}
	\item Basic probability theory and probability theory in context of BNs (hard math).
	\item Inference methods\,--\,stochastic (weighted sampling, Markov chain Monte-Carlo), exact (variable elimination, Belief-Net-Ask), approximate (message passing methods). Although not all are described in this thesis as they are not the key topic.
	\item Structure learning
	\item Attended on-line course Probabilistic Graphical Models taught by professor Daphne Koller at Stanford University.
	\item Implemented factors and their operations\,--\,enables sum-product and variable elimination inference algorithms.
\end{itemize}
What I want to do:
\begin{itemize}
	\item Study variants of stochastic sampling methods~\cite{neal93} if the ones described turn out to be unsatisfactory.
	\item Study modifications of structure learning.
\end{itemize}
\end{comment}






\begin{comment}
\chapter{Původní text šablony}
Abychom mohli napsat odborný text jasně a~srozumitelně, musíme splnit několik základních předpokladů:
\begin{itemize}
\item Musíme mít co říci,
\item musíme vědět, komu to chceme říci,
\item musíme si dokonale promyslet obsah,
\item musíme psát strukturovaně. 
\end{itemize}

Tyto a další pokyny jsou dostupné též na školních internetových stránkách \cite{fitWeb}.

Přehled základů typografie a tvorby dokumentů s využitím systému \LaTeX je 
uveden v~\cite{Rybicka}.

\section{Musíme mít co říci}
Dalším důležitým předpokladem dobrého psaní je {\it psát pro někoho}. Píšeme-li si poznámky sami pro sebe, píšeme je jinak než výzkumnou zprávu, článek, diplomovou práci, knihu nebo dopis. Podle předpokládaného čtenáře se rozhodneme pro způsob psaní, rozsah informace a~míru detailů.

\section{Musíme vědět, komu to chceme říci}
Dalším důležitým předpokladem dobrého psaní je psát pro někoho. Píšeme-li si poznámky sami pro sebe, píšeme je jinak než výzkumnou zprávu, článek, diplomovou práci, knihu nebo dopis. Podle předpokládaného čtenáře se rozhodneme pro způsob psaní, rozsah informace a~míru detailů.

\section{Musíme si dokonale promyslet obsah}
Musíme si dokonale promyslet a~sestavit obsah sdělení a~vytvořit pořadí, v~jakém chceme čtenáři své myšlenky prezentovat. 
Jakmile víme, co chceme říci a~komu, musíme si rozvrhnout látku. Ideální je takové rozvržení, které tvoří logicky přesný a~psychologicky stravitelný celek, ve kterém je pro všechno místo a~jehož jednotlivé části do sebe přesně zapadají. Jsou jasné všechny souvislosti a~je zřejmé, co kam patří.

Abychom tohoto cíle dosáhli, musíme pečlivě organizovat látku. Rozhodneme, co budou hlavní kapitoly, co podkapitoly a~jaké jsou mezi nimi vztahy. Diagramem takové organizace je graf, který je velmi podobný stromu, ale ne řetězci. Při organizaci látky je stejně důležitá otázka, co do osnovy zahrnout, jako otázka, co z~ní vypustit. Příliš mnoho podrobností může čtenáře právě tak odradit jako žádné detaily.

Výsledkem této etapy je osnova textu, kterou tvoří sled hlavních myšlenek a~mezi ně zařazené detaily.

\section{Musíme psát strukturovaně} 
Musíme začít psát strukturovaně a~současně pracujeme na co nejsrozumitelnější formě, včetně dobrého slohu a~dokonalého značení. 
Máme-li tedy myšlenku, představu o~budoucím čtenáři, cíl a~osnovu textu, můžeme začít psát. Při psaní prvního konceptu se snažíme zaznamenat všechny své myšlenky a~názory vztahující se k~jednotlivým kapitolám a~podkapitolám. Každou myšlenku musíme vysvětlit, popsat a~prokázat. Hlavní myšlenku má vždy vyjadřovat hlavní věta a~nikoliv věta vedlejší.

I k~procesu psaní textu přistupujeme strukturovaně. Současně s~tím, jak si ujasňujeme strukturu písemné práce, vytváříme kostru textu, kterou postupně doplňujeme. Využíváme ty prostředky DTP programu, které podporují strukturovanou stavbu textu (předdefinované typy pro nadpisy a~bloky textu). 


\chapter{Několik formálních pravidel}
Naším cílem je vytvořit jasný a~srozumitelný text. Vyjadřujeme se proto přesně, píšeme dobrou češtinou (nebo zpravidla angličtinou) a~dobrým slohem podle obecně přijatých zvyklostí. Text má upravit čtenáři cestu k~rychlému pochopení problému, předvídat jeho obtíže a~předcházet jim. Dobrý sloh předpokládá bezvadnou gramatiku, správnou interpunkci a~vhodnou volbu slov. Snažíme se, aby náš text nepůsobil příliš jednotvárně používáním malého výběru slov a~tím, že některá zvlášť oblíbená slova používáme příliš často. Pokud používáme cizích slov, je samozřejmým předpokladem, že známe jejich přesný význam. Ale i~českých slov musíme používat ve správném smyslu. Např. platí jistá pravidla při používání slova {\it zřejmě}. Je {\it zřejmé} opravdu zřejmé? A~přesvědčili jsme se, zda to, co je {\it zřejmé} opravdu platí? Pozor bychom si měli dát i~na příliš časté používání zvratného se. Například obratu {\it dokázalo se}, že... zásadně nepoužíváme. Není špatné používat autorského {\it my}, tím předpokládáme, že něco řešíme, nebo například zobecňujeme spolu se čtenářem. V~kvalifikačních pracích použijeme autorského {\it já} (například když vymezujeme podíl vlastní práce vůči převzatému textu), ale v~běžném textu se nadměrné používání první osoby jednotného čísla nedoporučuje.

Za pečlivý výběr stojí i~symbolika, kterou používáme ke {\it značení}. Máme tím na mysli volbu zkratek a~symbolů používaných například pro vyjádření typů součástek, pro označení hlavních činností programu, pro pojmenování ovládacích kláves na klávesnici, pro pojmenování proměnných v~matematických formulích a~podobně. Výstižné a~důsledné značení může čtenáři při četbě textu velmi pomoci. Je vhodné uvést seznam značení na začátku textu. Nejen ve značení, ale i~v~odkazech a~v~celkové tiskové úpravě je důležitá důslednost.

S tím souvisí i~pojem z~typografie nazývaný {\it vyznačování}. Zde máme na mysli způsob sazby textu pro jeho zvýraznění. Pro zvolené značení by měl být zvolen i~způsob vyznačování v~textu. Tak například klávesy mohou být umístěny do obdélníčku, identifikátory ze zdrojového textu mohou být vypisovány {\tt písmem typu psací stroj} a~podobně.

Uvádíme-li některá fakta, neskrýváme jejich původ a~náš vztah k~nim. Když něco tvrdíme, vždycky výslovně uvedeme, co z~toho bylo dokázáno, co teprve bude dokázáno v~našem textu a~co přebíráme z~literatury s~uvedením odkazu na příslušný zdroj. V~tomto směru nenecháváme čtenáře nikdy na pochybách, zda jde o~myšlenku naši nebo převzatou z~literatury.

Nikdy neplýtváme čtenářovým časem výkladem triviálních a~nepodstatných informací. Neuvádíme rovněž několikrát totéž jen jinými slovy. Při pozdějších úpravách textu se nám může některá dříve napsaná pasáž jevit jako zbytečně podrobná nebo dokonce zcela zbytečná. Vypuštění takové pasáže nebo alespoň její zestručnění přispěje k~lepší čitelnosti práce! Tento krok ale vyžaduje odvahu zahodit čas, který jsme jejímu vytvoření věnovali. 


\chapter{Nikdy to nebude naprosto dokonalé}
Když jsme už napsali vše, o~čem jsme přemýšleli, uděláme si den nebo dva dny volna a~pak si přečteme sami rukopis znovu. Uděláme ještě poslední úpravy a~skončíme. Jsme si vědomi toho, že vždy zůstane něco nedokončeno, vždy existuje lepší způsob, jak něco vysvětlit, ale každá etapa úprav musí být konečná.


\chapter{Typografické a~jazykové zásady}
Při tisku odborného textu typu {\it technická zpráva} (anglicky {\it technical report}), ke kterému patří například i~text kvalifikačních prací, se často volí formát A4 a~často se tiskne pouze po jedné straně papíru. V~takovém případě volte levý okraj všech stránek o~něco větší než pravý -- v~tomto místě budou papíry svázány a~technologie vazby si tento požadavek vynucuje. Při vazbě s~pevným hřbetem by se levý okraj měl dělat o~něco širší pro tlusté svazky, protože se stránky budou hůře rozevírat a~levý okraj se tak bude oku méně odhalovat.

Horní a~spodní okraj volte stejně veliký, případně potištěnou část posuňte mírně nahoru (horní okraj menší než dolní). Počítejte s~tím, že při vazbě budou okraje mírně oříznuty.

Pro sazbu na stránku formátu A4 je vhodné používat pro základní text písmo stupně (velikosti) 11 bodů. Volte šířku sazby 15 až 16 centimetrů a~výšku 22 až 23 centimetrů (včetně případných hlaviček a~patiček). Proklad mezi řádky se volí 120 procent stupně použitého základního písma, což je optimální hodnota pro rychlost čtení souvislého textu. V~případě použití systému LaTeX ponecháme implicitní nastavení. Při psaní kvalifikační práce se řiďte příslušnými závaznými požadavky.

Stupeň písma u~nadpisů různé úrovně volíme podle standardních typografických pravidel. 
Pro všechny uvedené druhy nadpisů se obvykle používá polotučné nebo tučné písmo (jednotně buď všude polotučné nebo všude tučné). Proklad se volí tak, aby se následující text běžných odstavců sázel pokud možno na {\it pevný rejstřík}, to znamená jakoby na linky s~předem definovanou a~pevnou roztečí.

Uspořádání jednotlivých částí textu musí být přehledné a~logické. Je třeba odlišit názvy kapitol a~podkapitol -- píšeme je malými písmeny kromě velkých začátečních písmen. U~jednotlivých odstavců textu odsazujeme první řádek odstavce asi o~jeden až dva čtverčíky (vždy o~stejnou, předem zvolenou hodnotu), tedy přibližně o~dvě šířky velkého písmene M základního textu. Poslední řádek předchozího odstavce a~první řádek následujícího odstavce se v~takovém případě neoddělují svislou mezerou. Proklad mezi těmito řádky je stejný jako proklad mezi řádky uvnitř odstavce.

Při vkládání obrázků volte jejich rozměry tak, aby nepřesáhly oblast, do které se tiskne text (tj. okraje textu ze všech stran). Pro velké obrázky vyčleňte samostatnou stránku. Obrázky nebo tabulky o~rozměrech větších než A4 umístěte do písemné zprávy formou skládanky všité do přílohy nebo vložené do záložek na zadní desce.

Obrázky i~tabulky musí být pořadově očíslovány. Číslování se volí buď průběžné v~rámci celého textu, nebo -- což bývá praktičtější -- průběžné v~rámci kapitoly. V~druhém případě se číslo tabulky nebo obrázku skládá z~čísla kapitoly a~čísla obrázku/tabulky v~rámci kapitoly -- čísla jsou oddělena tečkou. Čísla podkapitol nemají na číslování obrázků a~tabulek žádný vliv.

Tabulky a~obrázky používají své vlastní, nezávislé číselné řady. Z toho vyplývá, že v~odkazech uvnitř textu musíme kromě čísla udat i~informaci o~tom, zda se jedná o~obrázek či tabulku (například ``... {\it viz tabulka 2.7} ...''). Dodržování této zásady je ostatně velmi přirozené.

Pro odkazy na stránky, na čísla kapitol a~podkapitol, na čísla obrázků a~tabulek a~v~dalších podobných příkladech využíváme speciálních prostředků DTP programu, které zajistí vygenerování správného čísla i~v~případě, že se text posune díky změnám samotného textu nebo díky úpravě parametrů sazby. Příkladem takového prostředku v~systému LaTeX je odkaz na číslo odpovídající umístění značky v~textu, například návěští ($\backslash${\tt ref\{navesti\}} -- podle umístění návěští se bude jednat o~číslo kapitoly, podkapitoly, obrázku, tabulky nebo podobného číslovaného prvku), na stránku, která obsahuje danou značku ($\backslash${\tt pageref\{navesti\}}), nebo na literární odkaz ($\backslash${\tt cite\{identifikator\}}).

Rovnice, na které se budeme v~textu odvolávat, opatříme pořadovými čísly při pravém okraji příslušného řádku. Tato pořadová čísla se píší v~kulatých závorkách. Číslování rovnic může být průběžné v~textu nebo v~jednotlivých kapitolách.

Jste-li na pochybách při sazbě matematického textu, snažte se dodržet způsob sazby definovaný systémem LaTeX. Obsahuje-li vaše práce velké množství matematických formulí, doporučujeme dát přednost použití systému LaTeX.

Mezeru neděláme tam, kde se spojují číslice s~písmeny v~jedno slovo nebo v~jeden znak -- například {\it 25krát}.

Členicí (interpunkční) znaménka tečka, čárka, středník, dvojtečka, otazník a~vykřičník, jakož i~uzavírací závorky a~uvozovky se přimykají k~předcházejícímu slovu bez mezery. Mezera se dělá až za nimi. To se ovšem netýká desetinné čárky (nebo desetinné tečky). Otevírací závorka a~přední uvozovky se přimykají k~následujícímu slovu a~mezera se vynechává před nimi -- (takto) a~``takto''.

Pro spojovací a~rozdělovací čárku a~pomlčku nepoužíváme stejný znak. Pro pomlčku je vyhrazen jiný znak (delší). V~systému TeX (LaTeX) se spojovací čárka zapisuje jako jeden znak ``pomlčka'' (například ``Brno-město''), pro sázení textu ve smyslu intervalu nebo dvojic, soupeřů a~podobně se ve zdrojovém textu používá dvojice znaků ``pomlčka'' (například ``zápas Sparta -- Slavie''; ``cena 23--25 korun''), pro výrazné oddělení části věty, pro výrazné oddělení vložené věty, pro vyjádření nevyslovené myšlenky a~v~dalších situacích (viz Pravidla českého pravopisu) se používá nejdelší typ pomlčky, která se ve zdrojovém textu zapisuje jako trojice znaků ``pomlčka'' (například ``Další pojem --- jakkoliv se může zdát nevýznamný --- bude neformálně definován v~následujícím odstavci.''). Při sazbě matematického mínus se při sazbě používá rovněž odlišný znak. V~systému TeX je ve zdrojovém textu zapsán jako normální mínus (tj. znak ``pomlčka''). Sazba v~matematickém prostředí, kdy se vzoreček uzavírá mezi dolary, zajistí vygenerování správného výstupu.

Lomítko se píše bez mezer. Například školní rok 2008/2009.

Pravidla pro psaní zkratek jsou uvedena v~Pravidlech českého pravopisu \cite{Pravidla}. I~z~jiných důvodů je vhodné, abyste tuto knihu měli po ruce. 


\section{Co to je normovaná stránka?}
Pojem {\it normovaná stránka} se vztahuje k~posuzování objemu práce, nikoliv k~počtu vytištěných listů. Z historického hlediska jde o~počet stránek rukopisu, který se psal psacím strojem na speciální předtištěné formuláře při dodržení průměrné délky řádku 60 znaků a~při 30 řádcích na stránku rukopisu. Vzhledem k~zápisu korekturních značek se používalo řádkování 2 (ob jeden řádek). Tyto údaje (počet znaků na řádek, počet řádků a~proklad mezi nimi) se nijak nevztahují ke konečnému vytištěnému výsledku. Používají se pouze pro posouzení rozsahu. Jednou normovanou stránkou se tedy rozumí 60*30 = 1800 znaků. Obrázky zařazené do textu se započítávají do rozsahu písemné práce odhadem jako množství textu, které by ve výsledném dokumentu potisklo stejně velkou plochu.

Orientační rozsah práce v~normostranách lze v~programu Microsoft Word zjistit pomocí funkce {\it Počet slov} v~menu {\it Nástroje}, když hodnotu {\it Znaky (včetně mezer)} vydělíte konstantou 1800. Do rozsahu práce se započítává pouze text uvedený v~jádru práce. Části jako abstrakt, klíčová slova, prohlášení, obsah, literatura nebo přílohy se do rozsahu práce nepočítají. Je proto nutné nejdříve označit jádro práce a~teprve pak si nechat spočítat počet znaků. Přibližný rozsah obrázků odhadnete ručně. Podobně lze postupovat i~při použití OpenOffice. Při použití systému LaTeX pro sazbu je situace trochu složitější. Pro hrubý odhad počtu normostran lze využít součet velikostí zdrojových souborů práce podělený konstantou cca 2000 (normálně bychom dělili konstantou 1800, jenže ve zdrojových souborech jsou i~vyznačovací příkazy, které se do rozsahu nepočítají). Pro přesnější odhad lze pak vyextrahovat holý text z~PDF (např. metodou cut-and-paste nebo {\it Save as Text...}) a~jeho velikost podělit konstantou 1800. 


\chapter{Závěr}
Závěrečná kapitola obsahuje zhodnocení dosažených výsledků se zvlášť vyznačeným vlastním přínosem studenta. Povinně se zde objeví i zhodnocení z pohledu dalšího vývoje projektu, student uvede náměty vycházející ze zkušeností s řešeným projektem a uvede rovněž návaznosti na právě dokončené projekty.
\end{comment}
%=========================================================================
%begin-of-inserted-footer











% Pouzita literatura
  % ----------------------------------------------
\ifczech
  \bibliographystyle{czechiso}
\else 
  \bibliographystyle{plain}
%  \bibliographystyle{alpha}
\fi
  \begin{flushleft}
  \bibliography{literatura} % viz. literatura.bib
  \end{flushleft}
  \appendix
  
  \input{prilohy} % viz. prilohy.tex
\end{document}
